{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp4sX9VE4SdE6zI+/GwYQt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sqpoonz/esomatec/blob/main/Modelmaker_esomatec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRYjtwRZGBOI"
      },
      "source": [
        "\n",
        "##Step 1\n",
        "### Installieren der Packeges\n",
        "Model Maker packages + pycocotools library wird installiert (wird für die Auswertung benötigt) \n",
        "\n",
        " [GitHub repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beim Aufbau vom Modelmaker, sowie auch beim importieren kommen Fehler die ignoriert werden können."
      ],
      "metadata": {
        "id": "8AuzK5qCaaOh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35BJmtVpAP_n",
        "outputId": "223c0117-4ffc-42f4-abed-a91556a2ee2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 621 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 30.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 19.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 34.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 39.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 27.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 44.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 37.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 54.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 88 kB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 49.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 37 kB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 208 kB 53.2 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tflite-model-maker\n",
        "!pip install -q tflite-support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4QQTXHHATDS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import ExportFormat, QuantizationConfig\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "from tflite_support import metadata\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2\n",
        "### Hochladen der Zip Datei (Bilder+XML)"
      ],
      "metadata": {
        "id": "dTG8FkMKiKzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/images\n",
        "!unzip -q images.zip -d /content/images/all\n",
        "!mkdir /content/images/train; mkdir /content/images/validation"
      ],
      "metadata": {
        "id": "q7IEvhTFQjBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Holt sich die split.py Datei womit die Bilder+XML in die Ordner gepackt werden.\n",
        "\n",
        " (glaube hab es auf 90/10 aufgeteilt. kann angepasst werden 15-20% sollten aber für Validation höchstens genommen werden.\n"
      ],
      "metadata": {
        "id": "DSmefU1MiT1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/sqpoonz/esomatec/main/split.py\n",
        "!python split.py"
      ],
      "metadata": {
        "id": "ai6f2gL3Qi8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxh3KInCFeB-"
      },
      "source": [
        "## Step 3\n",
        "\n",
        "### Step 1: Laden der Bilder in train_data/val_data\n",
        "\n",
        "* Bilder in  `train_data` werden benutzt um das Detection Model zu trainieren.\n",
        "* Bilder in `val_data` wird benutzt um das Model zu testen, wie sich das Model zu neuen nicht gesehenen Bildern macht."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiAahdsQAdT7"
      },
      "outputs": [],
      "source": [
        "train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    'images/train',\n",
        "    'images/train',\n",
        "    ['0', '1','2','3','4','5','6','7','8','9','Unknown']\n",
        ")\n",
        "\n",
        "val_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    'images/validation',\n",
        "    'images/validation',\n",
        "    ['0', '1','2','3','4','5','6','7','8','9','Unknown']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNRhB8N7GHXj"
      },
      "source": [
        "## Step 4\n",
        "### Auswahl der Architektur vom Model\n",
        "\n",
        " Auswahl zwischen EfficientDet-Lite[0-4]  \n",
        " [EfficientDet architecture](https://arxiv.org/abs/1911.09070)\n",
        "\n",
        "Durchschnittliche Performance: Laufzeit Geschwindigkeit <> Durchschnittliche Genauigkeit.\n",
        "\n",
        "| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n",
        "|--------------------|-----------|---------------|----------------------|\n",
        "| EfficientDet-Lite0 | 4.4       | 146           | 25.69%               |\n",
        "| EfficientDet-Lite1 | 5.8       | 259           | 30.55%               |\n",
        "| EfficientDet-Lite2 | 7.2       | 396           | 33.97%               |\n",
        "| EfficientDet-Lite3 | 11.4      | 716           | 37.70%               |\n",
        "| EfficientDet-Lite4 | 19.9      | 1886          | 41.96%               |\n",
        "\n",
        "Durchschnitt wurde auf einem RasperryPi4 gemacht. Der Nvidia Jetson Nano Orin ist deutlich schneller.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spec = model_spec.get('efficientdet_lite0')"
      ],
      "metadata": {
        "id": "8Uw31Z3P8ege"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aeDU4mIM4ft"
      },
      "source": [
        "##Step 5\n",
        "### TensorFLow Model mit der training_data trainieren\n",
        "wird einige Stunden beim vollen Model benötigen.\n",
        "\"Kleine Models\" benötigen 1-2STD.\n",
        "\n",
        "Beim \"über trainieren\" abbrechen durch Doppelklick auf den Run.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "* Set `epochs = 20`, which means it will go through the training dataset 20 times. You can look at the validation accuracy during training and stop when you see validation loss (`val_loss`) stop decreasing to avoid overfitting.\n",
        "* Set `batch_size = 4` here so you will see that it takes 15 steps to go through the 62 images in the training dataset.\n",
        "* Set `train_whole_model=True` to fine-tune the whole model instead of just training the head layer to improve accuracy. The trade-off is that it may take longer to train the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = object_detector.create(train_data, model_spec=spec, batch_size=4, train_whole_model=True, epochs=20, validation_data=val_data)"
      ],
      "metadata": {
        "id": "wQF-KAEB9LDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB4hKeerMmh4"
      },
      "source": [
        "##Step 6\n",
        "### Modelauswertung bei noch nicht zuvor gesehenen Bildern von der val_data (Step 6+7 Dauern länger nicht abbrechen).\n",
        "\n",
        "(die Modelauswertung, sowie das Exportieren können eine ewigkeit Dauern ganz normal.\n",
        "Auswertungs metrics --> [COCO](https://cocodataset.org/#detection-eval)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_data)"
      ],
      "metadata": {
        "id": "Mw0Cmnli9O4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NARVYk9rGLIl"
      },
      "source": [
        "##Step 7\n",
        "### Exportieren vom TFLite Model\n",
        "\n",
        "[full integer quantization](https://www.tensorflow.org/lite/performance/post_training_integer_quant). "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(export_dir='.', tflite_filename='detect.tflite')"
      ],
      "metadata": {
        "id": "2iMIHQbB9RXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZcBmEigOCO3"
      },
      "source": [
        "##Step 8\n",
        "### Auswertung vom TFLite Model\n",
        "Exportiertes TFLite Model wird mit der Genauigkeit vom Originalen TFLite Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "Several factors can affect the model accuracy when exporting to TFLite:\n",
        "* [Quantization](https://www.tensorflow.org/lite/performance/model_optimization) helps shrinking the model size by 4 times at the expense of some accuracy drop.\n",
        "* The original TensorFlow model uses per-class [non-max supression (NMS)](https://www.coursera.org/lecture/convolutional-neural-networks/non-max-suppression-dvrjH) for post-processing, while the TFLite model uses global NMS that's much faster but less accurate.\n",
        "Keras outputs maximum 100 detections while tflite outputs maximum 25 detections.\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate_tflite('detect.tflite', val_data)"
      ],
      "metadata": {
        "id": "adlQDdtB9Vdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download TFLite Model"
      ],
      "metadata": {
        "id": "esxoU-vojHKS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "v7zgUkdOUUnD",
        "outputId": "03467f8e-1a52-41c1-d596-93fa75ce1fb6"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_88525e82-bbae-414d-87ff-ec2b93dde3b2\", \"android.tflite\", 4427830)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download the TFLite model to your local computer.\n",
        "from google.colab import files\n",
        "files.download('detect.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________________"
      ],
      "metadata": {
        "id": "ae8DO1xWhdRe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWP3fEPaGNvd"
      },
      "source": [
        "##Step 9 (Wird nur für ein Google Coral EdgeTPU TFlite Model benötigt, noch nicht mit Nvidia Jetson Nano Oring getestet)\n",
        "### Compile the model for EdgeTPU\n",
        "\n",
        "Zum Nutzen vom Coral EdgeTPU muss dieser+libary erst noch auf den Nvidia sbc installiert werden\n",
        "\n",
        "[Google Coral EdgeTPU](https://coral.ai/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK6AN1xVAsCb",
        "outputId": "0a199dc3-a4df-4b4b-ef2b-b9d88b14cb53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  59000      0 --:--:-- --:--:-- --:--:-- 59000\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:4 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,722 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,398 kB]\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:13 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:14 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,327 B]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,434 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:17 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [786 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,810 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,835 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,213 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [927 kB]\n",
            "Get:25 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.7 kB]\n",
            "Fetched 12.8 MB in 3s (4,420 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler\n",
            "0 upgraded, 1 newly installed, 0 to remove and 61 not upgraded.\n",
            "Need to get 7,913 kB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\n",
            "Fetched 7,913 kB in 0s (20.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "(Reading database ... 155062 files and directories currently installed.)\n",
            "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (16.0) ...\n",
            "Setting up edgetpu-compiler (16.0) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzF6u0FZTAjF"
      },
      "source": [
        "Before compiling the `.tflite` file for the Edge TPU, it's important to consider whether your model will fit into the Edge TPU memory. \n",
        "\n",
        "The Edge TPU has approximately 8 MB of SRAM for [caching model paramaters](https://coral.ai/docs/edgetpu/compiler/#parameter-data-caching), so any model close to or over 8 MB will not fit onto the Edge TPU memory. That means the inference times are longer, because some model parameters must be fetched from the host system memory.\n",
        "\n",
        "One way to elimiate the extra latency is to use [model pipelining](https://coral.ai/docs/edgetpu/pipeline/), which splits the model into segments that can run on separate Edge TPUs in series. This can significantly reduce the latency for big models.\n",
        "\n",
        "The following table provides recommendations for the number of Edge TPUs to use with each EfficientDet-Lite model.\n",
        "\n",
        "| Model architecture | Minimum TPUs | Recommended TPUs\n",
        "|--------------------|-------|-------|\n",
        "| EfficientDet-Lite0 | 1     | 1     |\n",
        "| EfficientDet-Lite1 | 1     | 1     |\n",
        "| EfficientDet-Lite2 | 1     | 2     |\n",
        "| EfficientDet-Lite3 | 2     | 2     |\n",
        "| EfficientDet-Lite4 | 2     | 3     |\n",
        "\n",
        "If you need extra Edge TPUs for your model, then update `NUMBER_OF_TPUS` here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyptUjakAwzz",
        "outputId": "7a3dad3b-eeb4-45e1-fb68-f0436ac5a933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Model compiled successfully in 3127 ms.\n",
            "\n",
            "Input model: android.tflite\n",
            "Input size: 4.22MiB\n",
            "Output model: android_edgetpu.tflite\n",
            "Output size: 5.57MiB\n",
            "On-chip memory used for caching model parameters: 4.21MiB\n",
            "On-chip memory remaining for caching model parameters: 3.29MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 267\n",
            "Operation log: android_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 264\n",
            "Number of operations that will run on CPU: 3\n",
            "See the operation log file for individual operation details.\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n"
          ]
        }
      ],
      "source": [
        "NUMBER_OF_TPUS = 5\n",
        "\n",
        "!edgetpu_compiler detect.tflite --num_segments=$NUMBER_OF_TPUS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Copy Metadata from tlfite model into the edgetpu Model and Download it"
      ],
      "metadata": {
        "id": "6BMzr-x_j5ll"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LY1WrgMJBFd"
      },
      "outputs": [],
      "source": [
        "populator_dst = metadata.MetadataPopulator.with_model_file('detect_edgetpu.tflite')\n",
        "\n",
        "with open('detect.tflite', 'rb') as f:\n",
        "  populator_dst.load_metadata_and_associated_files(f.read())\n",
        "\n",
        "populator_dst.populate()\n",
        "updated_model_buf = populator_dst.get_model_buffer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VdRihInCJ3ie",
        "outputId": "f2c37370-6ec3-41e6-903d-22e49e2f7dea"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f466f03c-e5c8-4a91-a845-258a44b01400\", \"android_edgetpu.tflite\", 5844678)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download the TFLite model compiled for EdgeTPU to your local computer.\n",
        "from google.colab import files\n",
        "files.download('detect_edgetpu.tflite')"
      ]
    }
  ]
}